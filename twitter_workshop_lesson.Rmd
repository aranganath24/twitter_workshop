---
title: "Introduction to Twitter Data in R"
author: "Aditya Ranganath"
date: "12/6/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Libraries

```{r, message=FALSE}
library(rtweet)
library(httpuv)
library(tidyverse)
library(tidytext)
library(wordcloud2)
library(qdapRegex)
library(tm)
library(webshot)
library(htmlwidgets)
```

## Pull Data from the Twitter API via *rtweet* Package

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Add twitter datasets to avoid calling API in markdown file
setwd("/Users/adra7980/Documents/git_repositories/twitter_workshop/exported_data")
student_debt_tweets<-read_csv("student_debt_tweets.csv")
student_debt_capitalism_tweets<-read_csv("student_debt_capitalism_tweets.csv")
student_debt_capitalism_tweets_ALT<-read_csv("student_debt_capitalism_tweets_ALT.csv")
student_debt_OR_capitalism_tweets<-read_csv("student_debt_OR_capitalism_tweets.csv")
blm_tweets<-read_csv("blm_tweets.csv")
```


```{r, eval=F}
# Pull tweets with #CancelStudentDebt; returns 1000 most recent tweets; time by GMT
student_debt_tweets<-search_tweets(q="#CancelStudentDebt", 
                                   n=1000,
                                   include_rts=FALSE,
                                   `-filter`="replies",
                                   lang="en")
```

```{r, eval=F}
# Pull tweets with #CancelStudentDebt AND capitalism
student_debt_capitalism_tweets<-search_tweets(q="#CancelStudentDebt capitalism", 
                                              n=1000,
                                              include_rts=FALSE,
                                              `-filter`="replies",
                                              lang="en")
```

```{r, eval=F}
# Insteading of pulling from the API, you could also pull tweets with #CancelStudentDebt, and then query the text
# of these tweets locally using a stringr function

student_debt_capitalism_tweets_ALT<-student_debt_tweets %>% 
                                     filter(str_detect(text, "[Cc]apitalism"))
```


```{r, eval=F}
# Pull tweets with #CancelStudentDebt OR capitalism

student_debt_OR_capitalism_tweets<-search_tweets(q="#CancelStudentDebt OR capitalism", 
                                                 n=1000,
                                                 include_rts=FALSE,
                                                 `-filter`="replies",
                                                 lang="en")
```


```{r, eval=F}
# # Pull tweets from an account (doesn't have same time constraints)
# Pull last 3200 BLM tweets (note sometimes the query will return less than 3200 due to deletions)
blm_tweets<-get_timeline("@Blklivesmatter", n=3200)
```




```{r}
twitter_wordcloud<-function(twitterhandle, tweet_number){
  tweet_timeline<-get_timeline(twitterhandle, n=tweet_number)
  tweet_timeline_text<-str_c(tweet_timeline$text, collapse="")
  tweet_timeline_text<-str_remove_all(tweet_timeline_text, pattern='[:emoji:]')
  tweet_timeline_text<-tweet_timeline_text %>%
                              str_remove("\\n") %>%                   # remove linebreaks
                              rm_twitter_url() %>%                    # Remove URLS
                              rm_url() %>%
                              str_remove_all("#\\S+") %>%             # Remove any hashtags
                              str_remove_all("@\\S+") %>%             # Remove any @ mentions
                              removeWords(stopwords("english")) %>%   # Remove common words (a, the, it etc.)
                              removeNumbers() %>%
                              stripWhitespace() %>%
                              removeWords(c("amp")) %>% 
                              removePunctuation()

  textCorpus <- 
    Corpus(VectorSource(tweet_timeline_text)) %>%
    TermDocumentMatrix() %>%
    as.matrix()
  
  textCorpus <- sort(rowSums(textCorpus), decreasing=TRUE)
  textCorpus <- data.frame(word = names(textCorpus), freq=textCorpus, row.names = NULL)
  
  wordcloud <- wordcloud2(data = textCorpus, minRotation = 0, maxRotation = 0, ellipticity = 0.2)
  return(wordcloud)
  
}

```



```{r}
lebron_wordcloud<-twitter_wordcloud("KingJames", 400)
elon_wordcloud<-twitter_wordcloud("elonmusk", 400)
```


```{r}
elon_wordcloud
```

## next


ddddddddsfadfa
dafafadfafc

```{r}
lebron_wordcloud<-twitter_wordcloud("KingJames", 400)
lebron_wordcloud
```

https://github.com/Lchiffon/wordcloud2/issues/65



